{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Note:** Outputs have been cleared.",
   "id": "4f2b13a8770aaca9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.0591, 0.0526, 0.0591],\n",
    "                         std=[0.0936, 0.0823, 0.0838])\n",
    "])\n",
    "\n",
    "# These values were pre-computed using `compute_mean_std()`, found below\n",
    "# Global Mean: tensor([0.0591, 0.0526, 0.0591])\n",
    "# Global Std:  tensor([0.0936, 0.0823, 0.0838])"
   ],
   "id": "720a56856e016826",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class GZdataset(Dataset):\n",
    "    def __init__(self, catalog, image_dir, transform=None):\n",
    "        if isinstance(catalog, str):\n",
    "            self.catalog = pd.read_parquet(catalog)\n",
    "        else:\n",
    "            self.catalog = catalog\n",
    "\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.catalog)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.catalog.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row['filename'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        transformed_image = self.transform(image)\n",
    "\n",
    "        return transformed_image"
   ],
   "id": "b76dbadb2dae03dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "original_images_folder_path = '../gz/gz_candels/images' # relative path\n",
    "\n",
    "# Load the original catalogs\n",
    "train_catalog = pd.read_parquet('../gz/gz_candels/train_catalog.parquet')\n",
    "test_catalog = pd.read_parquet('../gz/gz_candels/test_catalog.parquet')\n",
    "\n",
    "# Sample images within their respective catalogs (reduced count from the original due to hardware constraints)\n",
    "train_subset_catalog = train_catalog.sample(16_000)\n",
    "test_subset_catalog = test_catalog.sample(4_000)\n",
    "\n",
    "# Save subsets to new parquet files (I put them on an external SSD)\n",
    "train_subset_catalog.to_parquet('/Volumes/Samsung T7 SSD/gz_candels_tensors/train_catalog.parquet')\n",
    "test_subset_catalog.to_parquet('/Volumes/Samsung T7 SSD/gz_candels_tensors/test_catalog.parquet')"
   ],
   "id": "682a1d3165830274",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_subset = GZdataset(\n",
    "    catalog=train_subset_catalog,\n",
    "    image_dir=original_images_folder_path,\n",
    "    transform=image_transform\n",
    ")\n",
    "\n",
    "test_subset = GZdataset(\n",
    "    catalog=test_subset_catalog,\n",
    "    image_dir=original_images_folder_path,\n",
    "    transform=image_transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(data_subset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_subset, batch_size=128, shuffle=False)"
   ],
   "id": "e3edb24cc7a51154",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert images to tensor files and save them\n",
    "train_tensor_list = []\n",
    "for batch in tqdm(train_loader):\n",
    "    train_tensor_list.append(batch)\n",
    "train_images_tensor = torch.cat(train_tensor_list)\n",
    "torch.save(train_images_tensor, '/Volumes/Samsung T7 SSD/gz_candels_tensors/train_images_tensor.pt')\n",
    "\n",
    "test_tensor_list = []\n",
    "for batch in tqdm(test_loader):\n",
    "    test_tensor_list.append(batch)\n",
    "test_images_tensor = torch.cat(test_tensor_list)\n",
    "torch.save(test_images_tensor, '/Volumes/Samsung T7 SSD/gz_candels_tensors/test_images_tensor.pt')"
   ],
   "id": "daf4cef149985704",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_mean_std(dataset, batch_size=128):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Accumulate sums and sums of squares separately for each channel.\n",
    "    sum_channels = torch.zeros(3)\n",
    "    sum_channels_sq = torch.zeros(3)\n",
    "    n_pixels_total = 0\n",
    "\n",
    "    for data in tqdm(dataloader, desc=\"Computing global mean/std\"):\n",
    "        b, c, h, w = data.shape\n",
    "\n",
    "        # Reshape to (B, C, H*W)\n",
    "        data = data.view(b, c, -1)\n",
    "\n",
    "        # Sum of values and squares in this batch per channel\n",
    "        sum_channels += data.sum(dim=(0, 2))\n",
    "        sum_channels_sq += (data ** 2).sum(dim=(0, 2))\n",
    "\n",
    "        n_pixels_total += b * h * w\n",
    "\n",
    "    # Compute mean and std across all pixels\n",
    "    mean_pixels = sum_channels / n_pixels_total\n",
    "    std_pixels = torch.sqrt(((sum_channels_sq / n_pixels_total) - (mean ** 2)))\n",
    "\n",
    "    return mean_pixels, std_pixels\n",
    "\n",
    "\n",
    "# Simple transform to not manipulate image data\n",
    "tensor_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "mean_std_dataset = GZdataset(\n",
    "    catalog=train_catalog,\n",
    "    image_dir=original_images_folder_path,\n",
    "    transform=tensor_transform\n",
    ")\n",
    "\n",
    "mean, std = compute_mean_std(mean_std_dataset)\n",
    "print(\"Global Mean:\", mean)\n",
    "print(\"Global Std: \", std)"
   ],
   "id": "6c280039514fa6d2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
